{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "class Weighted_Cross_Entropy_Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Weighted_Cross_Entropy_Loss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target, weights):\n",
    "        n, c, H, W = pred.shape\n",
    "        # Calculate log probabilities\n",
    "        logp = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        # Gather log probabilities with respect to target\n",
    "        logp = torch.gather(logp, 1, target.view(n, 1, H, W))\n",
    "\n",
    "        # Multiply with weights\n",
    "        weighted_logp = (logp * weights).view(n, -1)\n",
    "\n",
    "        # Rescale so that loss is in approx. same interval\n",
    "        weighted_loss = weighted_logp.sum(1) / weights.view(n, -1).sum(1)\n",
    "\n",
    "        # Average over mini-batch\n",
    "        weighted_loss = -weighted_loss.mean()\n",
    "\n",
    "        return weighted_loss\n",
    "\n",
    "# def class_weight(target):\n",
    "#     weight = torch.zeros(batch_size, H, W)\n",
    "#     for i in range(out_channels):\n",
    "#         i_t = i * torch.ones([batch_size, H, W], dtype=torch.long)\n",
    "#         loc_i = (target == i_t).to(torch.long)\n",
    "#         count_i = loc_i.view(out_channels, -1).sum(1)\n",
    "#         total = H*W\n",
    "#         weight_i = total / count_i\n",
    "#         weight_t = loc_i * weight_i.view(-1, 1, 1)\n",
    "#         weight += weight_t\n",
    "#     return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BU_Net_Loss(torch.nn.Module):\n",
    "    def __init__(self, weight=None):\n",
    "        super(BU_Net_Loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.cross_entropy_loss = Weighted_Cross_Entropy_Loss(weight)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        weights = self.compute_class_weight(target)\n",
    "        wce_loss = self.cross_entropy_loss(pred, target, weights)\n",
    "        dice = dice_loss(pred, target)\n",
    "        total_loss = wce_loss + dice\n",
    "        return total_loss\n",
    "    \n",
    "    def compute_class_weight(self, target):\n",
    "        n, H, W = target.size()\n",
    "        class_weights = torch.zeros(n, H, W).to(target.device)\n",
    "        for i in range(target.max() + 1):\n",
    "            mask = (target == i).float()\n",
    "            class_weight = 1.0 / (mask.sum() + 1e-6)\n",
    "            class_weights += mask * class_weight\n",
    "        return class_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용법 예시 ... ??\n",
    "- pred = torch.randn(8, 3, 256, 256)  # Example predictions\n",
    "- target = torch.randint(0, 3, (8, 256, 256))  # Example target\n",
    "- loss_fn = BU_Net_Loss()\n",
    "- loss = loss_fn(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Weighted Cross-Entropy Loss (WCE)\n",
    "\n",
    "클래스 분류를 위한 손실 함수이다. 클래스가 불균형한 경우, 각 클래스에 가중치를 부여하여 손실을 계산한다.\n",
    "\n",
    "- Dice Loss Coefficient (DLC)\n",
    "\n",
    "예측된 분할 영역과 실제 분할 영역의 최대 중첩을 찾기 위한 목적 함수이다. 주로 이미지 분할 작업에서 사용되며, 분할 성능을 향상시킨다.\n",
    "\n",
    "- Loss Function Formulation\n",
    "  - L total=WCE+DLC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
